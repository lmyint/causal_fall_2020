[["index.html", "STAT 451: Causal Inference Welcome!", " STAT 451: Causal Inference Welcome! Image source: IMDB. (Know how this relates to class? Tell the instructor!) This is the course website for STAT 451: Causal Inference at Macalester College for the Fall 2020 semester (Module 1). The content here was made by Leslie Myint and draws upon several resources, all of which are listed on the References page. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["references.html", "References Required references References for review Further exploration", " References Required references Causal Inference in Statistics: A Primer, by Judea Pearl, Madelyn Glymour, and Nicholas P. Jewell. PDF freely available online. (Referred to as “PRIMER”.) Causal Inference: What If, by Miguel A. Hernán and James M. Robins. PDF freely available online. (Referred to as “WHATIF”.) References for review STAT 155 Notes: An online set of notes for STAT 155 written by the Macalester statistics faculty. Probability Essentials: A YouTube video outlining some key ideas from probability that we will use in this course. This article by Eleanor Murray has a great explanation of the most common misinterpretation of confidence intervals. Further exploration The Book of Why: The New Science of Cause and Effect, by Judea Pearl and Dana Mackenzie (Amazon) Causality: Models, Reasoning, and Inference, by Judea Pearl (available as an eBook through Macalester’s library) edX course: Causal Diagrams: Draw Your Assumptions Before Your Conclusions Udemy course: Causal Data Science with Directed Acyclic Graphs "],["schedule.html", "Schedule", " Schedule The schedule below is a tentative outline of our plans for the module. If we need more time for digestion, there is flexibility in our plans to allow for that. Before each class period, please watch the indicated videos, complete required readings, and complete the associated Moodle checkpoint. Checkpoints are due at 2pm CST on the indicated day. For the most part, readings listed here are suggestions. They refer to sections in the PRIMER and WHATIF books (see References) and may be useful for alternate presentations of the concepts. When a reading is required, it will marked as (REQD). Week 1: Foundational Ideas (9/2 - 9/4) Day(s) Topic Videos/Readings Slides Checkpoint Solutions 9/2 Motivation and Review PDF link 9/3 Exchangeability Defining Causal Effects Exchangeability WHATIF: 2.1, 2.2, 3.1, 3.2 PDF PDF link link 9/4 Study Designs Study Designs in Causal Inference WHATIF: 2.1, 2.2, 3.1, 3.2 PDF link link Homework 1 due Sunday, 9/6 at midnight CST Week 2: Causal Graphs (9/8 - 9/11) Day(s) Topic Videos/Readings Slides Checkpoint Solutions 9/8 Causal Graphs as Statistical Models Introduction to Causal Graphs Causal Graphs as Statistical Models PRIMER: 1.4, 1.5 PDF PDF link link 9/9 Key Structures in Causal Graphs Key Structures in Causal Graphs PRIMER: 2.1 - 2.3 WHATIF: 6.1 - 6.3, 6.5 PDF link link 9/10 Graphical Structure of Confounding Causal and Noncausal Paths D-Separation PRIMER: 2.4 WHATIF: 7.1 - 7.4, 7.6 PDF PDF link link 9/11 Graphical Structure of Selection Bias (REQD) WHATIF: 8.1 - 8.3 Optional: 8.4 - 8.6 link Homework 2 due Sunday, 9/13 at midnight CST Week 3: Causal Graphs and Estimating Causal Effects (9/14 - 9/18) Day(s) Topic Videos/Readings Slides Checkpoint Solutions 9/14 Digestion day: Causal graphs and study designs Group discussion/reflection can be turned in as \"mini-homework\" for earning Mastery on causal graphs + study design objectives. 9/15 The Smoking-Birthweight Paradox (REQD) reading: The Birth Weight \"Paradox\" Uncovered? link 9/16-9/17 Regression for Estimating Causal Effects Asking Clear Questions and Building Graphs Estimating Causal Effects: Regression PDF PDF link 9/18 Inverse Probability Weighting Estimating Causal Effects: Inverse Probability Weighting WHATIF: 2.4 (parallels video) PRIMER: 3.6 (analgous viewpoint but different language than WHATIF) PDF link link Homework 3 due Sunday, 9/20 at midnight CST Week 4: Estimation and Sensitivity Analyses (9/21 - 9/25) Day(s) Topic Videos/Readings Slides Checkpoint Solutions 9/21, 9/23 Inverse Probability Weighting in Practice (REQD): WHATIF: 12.1, 12.2, 12.4 link 9/24 Time-Varying Treatments (REQD) WHATIF: 19.1 - 19.4 link link Homework 4 due Sunday, 9/27 at midnight CST Week 5: Sensitivity Analyses and Mediation (9/28 - 10/2) Day(s) Topic Videos/Readings Slides Checkpoint Solutions 9/28 Sensitivity Analyses for Unmeasured Variables Sensitivity Analyses for Unmeasured Variables PDF link 9/29 Causal Discovery Causal Discovery PDF link 10/1 Mediation Analysis Mediation Analysis&nbsp;(watch by 10/1) How racial discrimination in law enforcement actually works&nbsp;(REQD for 10/2) PDF link Homework 5 due Sunday, 10/4 at midnight CST "],["review-and-motivation.html", "Topic 1 Review and Motivation Learning Goals Slides Exercises", " Topic 1 Review and Motivation Learning Goals Identify when linear regression and when logistic regression would be appropriate Interpret coefficients from linear and logistic regression models with and without interaction Describe the 2 conditions/characteristics of a confounder Use a causal diagram (a graph) to depict the structure of relationships underlying confounding Explain how regression models provide a way to “adjust for” confounders Using the 2 characteristics of a confounder, explain how an “unadjusted” relationship is misleading Slides Slides from today are available here. Exercises Solutions to these exercises are available on Moodle. You can download a template RMarkdown file to start from here. We will look at (simulated) data from a study that looked at the effectiveness of chemotherapy for treating colon cancer. Chemotherapy is effectively a poison that kills cells in the body that are rapidly proliferating: these cells include the cancer cells (often in a mass called a tumor) but also cells in bone marrow involved in sustaining the immune system. In this study, researchers measured the following variables: pre_tumor_size: Tumor size at the start of the study (Small or Large). treated: ChemoYes if the patient received chemotherapy or ChemoNo if not. post_tumor_size: Tumor size 3 months after the start of the study (Small or Large). recovery: Yes if the patient fully recovered from their cancer after 1 year. No otherwise. You can read in the data as follows: chemo_study_data &lt;- readr::read_csv(&quot;https://www.dropbox.com/s/vl06j75a8afw8ct/chemo_study.csv?dl=1&quot;) Exercise 1: Plots and confounders The first step in any data analysis is to visualize your data. Let’s refamiliarize ourselves with the ggplot2 package in R. It may be helpful to have this ggplot2 cheat sheet open. Make sure to load the ggplot2 package by including library(ggplot2) at the top of your RMarkdown document. Get a feel for the data by visualizing the distributions of all 4 variables individually (4 plots total). Your code should look something like below. ggplot(chemo_study_data, aes(x = pre_tumor_size)) + ??? Is pre-treatment tumor size predictive of whether or not a patient received chemotherapy? Make a plot to assess this, and briefly state what conclusions can be drawn from the plot. (Hint: it will be helpful to look at the second page of the cheat sheet in the section labeled “Position Adjustments”.) ggplot(chemo_study_data, aes(x = pre_tumor_size, fill = treated)) + ??? Is pre-treatment tumor size predictive of whether or not a patient recovered? Make a plot, and briefly state your conclusions. A variable is a confounder if it is a common cause of both the treatment and outcome. This is shown in the diagram below. Given your results from parts b and c, could pre-treatment tumor size be a confounder of the relationship between chemotherapy treatment and recovery? Could post-treatment tumor size be a confounder of the relationship between chemotherapy treatment and recovery? Support your answer with plots and an explanation. Note: the causal relationships of interest so far can be depicted in a causal diagram, shown below. An arrow between two variables indicates that one is a cause of the other (an arrow points from a cause to its effect). Exercise 2: Implications of confounding What is the relationship between confounders and the saying “Correlation does not imply causation”? Explain how regression models can be used to remove the influence of confounding variables. Suppose that chemotherapy generally works to promote recovery. Suppose also that sicker patients tend to receive chemotherapy, and healthier patients tend to not receive chemotherapy. What would you expect if you directly compared recovery rates in the chemotherapy and standard of care patients (no adjustments for other variables)? What would you expect if you held appropriate confounders constant? Exercise 3: Logistic regression models We can model recovery using a logistic regression model (used when the outcome variable is binary). In R, we can fit a logistic regression model using code like the following: # Fit the model and store it in the &quot;mod&quot; object mod &lt;- glm(outcome_variable ~ predictor_variable1+predictor_variable2, family = &quot;binomial&quot;, data = your_data) # Display model output summary(mod) # Obtain confidence intervals (CIs) for model coefficients # (95% CIs by default) confint(mod) Fit a logistic regression model with only treatment as a predictor. Interpret the treatment coefficient. Is the sign of the coefficient what you expected? Why is this model misleading? Fit a logistic regression model that adjusts for pre-treatment tumor size. Interpret the treatment coefficient. Is the sign of the coefficient what you expected? Also report the 95% confidence interval for the treatment coefficient and what information you learn from it. (Side note: This article by Eleanor Murray has a great explanation of the most common misinterpretation of confidence intervals.) Fit a logistic regression model that adjusts for pre- and post-treatment tumor size. Interpret the treatment coefficient. Is the sign of the coefficient what you expected? Exercise 4: Warming up to causal ideas Consider the statement: “The causal effect of chemotherapy on recovery rates (as compared to no chemotherapy) is a change (difference) of 10%.” What do you think “causal effect” means? What would you like it to mean? Which model do you think best estimates the causal effect of chemotherapy on recovery rates? Explain. "],["exchangeability.html", "Topic 2 Exchangeability Pre-class work Learning Goals Exercises", " Topic 2 Exchangeability Pre-class work Videos/slides Defining Causal Effects: [video], [slides] Exchangeability: [video], [slides] Checkpoint questions: Link to Moodle checkpoint Which of the following is an example of an example of an average causal effect? Select all that apply. \\(E[Y^{a=1}]\\) \\(E[Y^{a=0}]\\) \\(E[Y^{a=1}]/E[Y^{a=0}]\\) \\(Y^{a=1}-Y^{a=0}\\) \\(E[Y^{a=1}-Y^{a=0}]\\) We want to estimate the causal effect of a new medication (treatment group) on cholesterol levels as compared to the medication that is currently the standard of care (control group). (The potential outcomes represent potential cholesterol levels.) Fatty food consumption is likely a factor that would lead to lack of exchangeability of the treated and untreated if doctors use fatty food consumption in their choice of medication to prescribe. Increased fatty food consumption generally leads to higher cholesterol levels. Suppose that the new medication truly does lead to lower cholesterol levels than the standard of care. Which of the following are correct? If those prescribed the new medication have HIGHER fatty food consumption than those prescribed the standard of care, then the beneficial impact of the new drug will be overestimated when directly comparing the treatment to the control group. If those prescribed the new medication have HIGHER fatty food consumption than those prescribed the standard of care, then the beneficial impact of the new drug will be underestimated when directly comparing the treatment to the control group. If those prescribed the new medication have LOWER fatty food consumption than those prescribed the standard of care, then the beneficial impact of the new drug will be overestimated when directly comparing the treatment to the control group. If those prescribed the new medication have LOWER fatty food consumption than those prescribed the standard of care, then the beneficial impact of the new drug will be underestimated when directly comparing the treatment to the control group. Continuing the medication-cholesterol example, what are two factors (other than fatty food consumption) that could contribute to a lack of exchangeability of the treatment groups? Explain your reasoning. Conditional exchangeability is marginal exchangeability within subsets of the data. TRUE FALSE Suppose that marginal exchangeability of the treated and untreated holds. Among the treated, we observe a mean outcome of 10. Among the untreated, we observe a mean outcome of 8. What can be said about \\(Y^{a=0}\\) among the treated and about \\(Y^{a=1}\\) among the untreated? We don’t know anything about those quantities because they are unobserved. Among the treated, the mean \\(Y^{a=0}\\) is 10. Among the untreated, the mean \\(Y^{a=1}\\) is 8. Among the treated, the mean \\(Y^{a=0}\\) is 8. Among the untreated, the mean \\(Y^{a=1}\\) is 10. Learning Goals Define an average causal effect in terms of potential outcomes EXCH1: Apply the concepts of marginal and conditional exchangeability to answer questions about (hypothetical) data on potential outcomes. EXCH2: Give examples of when marginal and conditional exchangeability would and would not hold in various data contexts. EXCH3: Explain why a direct comparison of the outcomes in the treated and untreated is misleading as an estimate of a causal effect. Exercises Solutions to these exercises are available on Moodle. Navigate to PollEverywhere for some warm-up exercises. If you attended, how was First Thursday for you? Otherwise, what’s a Mac tradition that you miss? Exercise 1 Suppose that we are trying to understand the causal effect of a personal finance course on the percent of earnings left in savings each month (abbreviated as “percent savings”). For the 500 people who took the course, we are able to collect data on percent savings and various other factors. We are also able to collect the same information from 500 people who did not take the course. Do you think that a comparison of percent savings in the course takers and non-takers would be a valid estimate of the average causal effect? Explain your viewpoint using the concepts of potential outcomes and exchangeability. One important factor to consider is the number of children that an individual has. Explain how this factor could contribute to a lack of exchangeability in the outcomes of the course takers and non-takers. As part of your explanation, discuss how observed outcomes compare to the missing potential outcomes. State any assumptions you make about the relationships between different factors. Do you think conditional exchangeability holds conditional on number of children? If yes, why? If no, what other factors might be needed to achieve conditional exchangeability? What is your thought process in thinking about other factors? Exercise 2 We have the data below on number of children (\\(Z\\)), treatment (course takers: \\(A = 1\\). course non-takers: \\(A = 0\\)), and the percent savings outcome (\\(Y^a\\)) categorized as either high (H) or low (L). Assuming that the course takers and non-takers are exchangeable conditional on number of children, estimate the average causal effect \\(P(Y^{a=1} = \\mathrm{high}) - P(Y^{a=0} = \\mathrm{high})\\). \\(n\\) \\(Z\\) \\(A\\) \\(Y^{a=1}\\) \\(Y^{a=0}\\) 10 2 1 7 H, 3 L ? 10 1 1 6 H, 4 L ? 10 0 1 5 H, 5 L ? 30 2 0 ? 18 H, 12 L 40 1 0 ? 20 H, 20 L 50 0 0 ? 20 H, 30 L Exercise 3 While \\(Y^a\\) denotes the potential outcome under treatment \\(A = a\\), \\(Y\\) denotes the observed outcome. (For the treated, \\(Y = Y^{a=1}\\). For the untreated, \\(Y = Y^{a=0}\\).) Is it possible for marginal exchangeability to hold but for \\(Y\\) and \\(A\\) to be dependent? Explain using a numerical or graphical example. Exercise 4 Assuming that we have exchangeability of the course takers and non-takers conditional on number of children (\\(Z\\)) and use of public transportation (\\(W\\)), how might a regression model be used to estimate the average causal effect of the personal finance course? Take a few minutes to reflect on today’s ideas by filling out an exit ticket. "],["study-designs-overview.html", "Topic 3 Study Designs Overview Pre-class work Learning Goals Exercises", " Topic 3 Study Designs Overview Pre-class work Videos/slides Study Designs in Causal Inference: [video], [slides] Checkpoint questions: Link to Moodle checkpoint We are analyzing survey data collected by the Minnesota Department of Health to understand the effect of vaping during adolescence on adulthood respiratory problems. What study design best describes this? Randomized experiment Instrumental variables design Regression discontinuity Interrupted time series General observational study A state program only has the budget to fund a social services program in the 10 poorest counties in the state. We want to study the effect of this program on county-level social and economic indicators. What study design best describes this? Randomized experiment Instrumental variables design Regression discontinuity Interrupted time series General observational study A hospital randomly puts up flyers throughout public hallways reminding people to get their flu shot. We want to study the effect of actually taking this year’s flu shot on risk of getting the flu. What study design best describes this? Randomized experiment Instrumental variables design Regression discontinuity Interrupted time series General observational study In at most two sentences, describe a general strategy that quasi-experimental studies use to try to achieve conditional exchangeability. Learning Goals DESI1: Explain how randomized experiments relate to exchangeability. DESI2: Explain how quasi-experimental and general observational studies relate to exchangeability. DESI3: Compare the strengths and weaknesses of different study designs for answering a research question. Exercises Solutions to these exercises are available on Moodle. Navigate to PollEverywhere for some warm-up exercises. What’s one thing you’re looking forward to this long weekend? Exercise 1 In a randomized experiment, participants are randomly assigned to receive either a new medication (\\(A = 1\\)) or the standard medication (\\(A = 0\\)) for cholesterol control. (Randomization is performed overall for all participants - not within subgroups.) The average cholesterol level in the new medication group is 130 mg/dL, and the average cholesterol level in the standard medication group is 140 mg/dL. Information on individuals’ family history of heart disease is also collected (\\(Z = 1\\) for a family history and \\(Z = 0\\) for no family history). What can be said about the potential outcome data in the table below? What would be an estimate of the average causal effect \\(E[Y^{a=1}-Y^{a=0}]\\)? \\(n\\) \\(Z\\) \\(A\\) \\(Y^{a=1}\\) \\(Y^{a=0}\\) 50 1 1 50 1 0 50 0 1 50 0 0 Exercise 2 A common use of regression discontinuity designs in policy research occurs when funding for a program is limited, and areas are ranked by need to determine whether they will receive the benefits of the program. Only areas with the greatest need receive program benefits. Explain how this type of design is attempting to create exchangeability. Do you think that this design is effective in that goal? Explain. Exercise 3 Consider the use of an advertisement to promote a health product. The ultimate goal is to understand the causal effect of the product on an outcome. How might advertisements be released to capitalize on an instrumental variables design? Explain how this type of design is attempting to create exchangeability. Do you think that this design is effective in that goal? Explain. Exercise 4 Of the three quasi-experimental study designs we’ve discussed (regression discontinuity, instrumental variables, and interrupted time series), which do you think is most effective in reaching exchangeability? Which do you think is least effective? Explain your thoughts. Take a few minutes to reflect on today’s ideas by filling out an exit ticket. "],["causal-graphs-as-statistical-models.html", "Topic 4 Causal Graphs as Statistical Models Pre-class work Learning Goals Simulating data in R Exercises", " Topic 4 Causal Graphs as Statistical Models Pre-class work Videos/slides Introduction to Causal Graphs: [video], [slides] Causal Graphs as Statistical Models: [video], [slides] Checkpoint questions: Link to Moodle checkpoint Which of the following graph properties characterize causal graphs? cyclic acyclic directed undirected complete For a directed graph with a node X: the parents of X are a subset of the ancestors of X. TRUE FALSE Apply the product decomposition rule using the Causal Markov assumption to express the joint distribution of variables in this graph: X –&gt; Y –&gt; Z Apply the product decomposition rule using the Causal Markov assumption to express the joint distribution of variables in this graph: Y &lt;– X –&gt; Z Learning Goals PGRA1: Apply the Causal Markov assumption to express the joint distribution of data. Simulate data from causal graphs under linear and logistic regression structural equation models. Formulate use cases of simulation to understand causal inference concepts Simulating data in R You can download a template RMarkdown file to start from here. Why simulate? Simulation is a very powerful tool for understanding statistical ideas. We can simulate (generate) data where we know the true underlying distribution, and we can then see how statistical methods perform on this data. For example: Do 95% confidence intervals really contain the true population value in 95% of samples? When is this not true? Does regression work to estimate causal effects when we have conditional exchangeability? Simulation functions in R R has functions to work with several probability distributions. For example, the following 4 functions work with the normal distribution: rnorm(): Generate a random number from a normal distribution pnorm(): Tail probability from a normal distribution dnorm(): Get density value from a normal distribution qnorm(): Get a quantile from a normal distribution There are r, p, d, and q functions for other distributions too (e.g., runif(), rbinom().) We’ll primarily use r functions to generate random numbers. rbinom(): # 4 different people each flip a fair coin once rbinom(4, size = 1, prob = 0.5) # 4 different people flip unfair coins # First 2 flip a coin with P(Heads) = 0.9 # Second 2 flip a coin with P(Heads) = 0.2 rbinom(4, size = 1, prob = c(0.9, 0.9, 0.2, 0.2)) # Write a command with rbinom() so that the result will definitively be 1,0,1 rnorm(): # 5 numbers from a normal distribution with mean 10 and SD 2 rnorm(5, mean = 10, sd = 2) # 3 numbers from 3 different normal distributions # Means = 10, 100, 1000. SD = 1 rnorm(3, mean = c(10, 100, 1000), sd = 1) # Write a command with rnorm() so that the result will definitively be 10,20 Simulating data from graphs+SEMs In this course, we’ll simulate data that come from graphs and their corresponding structural equation models. We’ll step through how to simulate data that come from this causal graph. Question: Using the Causal Markov Assumption, how can we express the joint distribution of this data? Consider the structural equation model (SEM) below that is associated with our causal graph: \\[ \\begin{align*} Z &amp;\\sim N(\\mu_Z = 40, \\sigma_Z = 5) \\\\ A &amp;\\sim \\mathrm{Binomial}(n = 1, p_A) \\\\ p_A: &amp;\\log\\left(\\frac{p_A}{1-p_A}\\right) = -1 + 0.05Z \\\\ Y &amp;\\sim N(\\mu_Y, \\sigma_Y = 1) \\\\ \\mu_Y &amp;= 30 + 5A + 2Z \\end{align*} \\] \\(Z\\) is an exogenous variable that follows a normal distribution with mean 40 and standard deviation 5. \\(A\\) is binary (binomial/Bernoulli) with probability of success \\(p_A\\) \\(p_A\\) depends on \\(Z\\) via a logistic regression model. \\(Y\\) is quantitative and follows a normal distribution. The mean \\(\\mu_Y\\) depends on \\(A\\) and \\(Z\\) via a linear regression model. Complete the code below to simulate data that follow this structural equation model. # Sample size n &lt;- 10000 # Simulate the Z variable Z &lt;- rnorm(?) # Simulate the A variable log_odds_A &lt;- -1 + 0.05*Z odds_A &lt;- exp(log_odds_A) p_A &lt;- odds_A/(1+odds_A) A &lt;- rbinom(?) # Simulate the Y variable mean_Y &lt;- 30 + ? Y &lt;- ? # Store all simulated variables in a dataset called sim_data sim_data &lt;- data.frame(Z, A, Y) Reproducibility At the top of code chunks where you perform simulation, use the set.seed() function to ensure that when you rerun the code, you get the same results: set.seed(451) # Your simulation code Exercises Solutions to these exercises are available on Moodle. What’s something that you enjoyed this long weekend? Exercise 1 Write the joint distribution of the data from the causal graph below using the Causal Markov Assumption. Then simulate data from the graph. You are free to choose your own structural equation model, but let \\(Z\\), \\(W\\), and \\(Y\\) be quantitative. Let \\(A\\) be binary. Use a sample size of 10,000 for your simulation. Based on the structural equation model you chose, what would you guess is the average causal effect of \\(A\\) on \\(Y\\)? Let’s consider simulating interventions using your SEM. If you were to force all study units to receive a certain value of treatment (either 0 or 1), how do you think the causal graph would change? Modify your simulation to reflect your thoughts from part c. Incorporate the code below into your simulation. # Scenario 1: Force all to be treated A_force_1 &lt;- rep(1, n) # Repeat the number 1 n times # Scenario 2: Force all to be treated A_force_0 &lt;- rep(0, n) # Repeat the number 0 n times # The treated potential outcome Y^{a=1} Y1 &lt;- ? # something with A_force_1 # The untreated potential outcome Y^{a=0} Y0 &lt;- ? # something with A_force_0 # Estimate the average causal effect mean(?) Was your intuition from part b close to the ACE that you estimated in the simulation? Interrupted times series in the news If you have time, discuss the Tweet below with your group. What does Liz Stuart mean by a “stark effect”? What might the trends look like if the effect weren’t so stark? What is the treatment? What evidence does this analysis provide? Is it strong evidence? Do you have any concerns? Wow this is a pretty compelling comparative interrupted time series graph. Don't usually see such a stark effect. https://t.co/VCPLwUrXby — Elizabeth Stuart (@Lizstuartdc) September 6, 2020 Take a few minutes to reflect on today’s ideas by filling out an exit ticket. "],["key-structures-in-causal-graphs.html", "Topic 5 Key Structures in Causal Graphs Pre-class work Learning Goals Exercises", " Topic 5 Key Structures in Causal Graphs Pre-class work Videos/slides Key Structures in Causal Graphs: [video], [slides] Checkpoint questions: Link to Moodle checkpoint Suppose that the variables A, B, and C in a causal graph are connected as such: A – B – C without knowledge of the arrow directions. If we only know that A and C are marginally dependent, which of the following structures are possible? A –&gt; B –&gt; C A &lt;– B &lt;– C A &lt;– B –&gt; C A –&gt; B &lt;– C If we know that A and C are conditionally dependent given B, which of the following structures are possible? A –&gt; B –&gt; C A &lt;– B &lt;– C A &lt;– B –&gt; C A –&gt; B &lt;– C If we know that A and C are marginally dependent and that A and C are conditionally independent given B, which of the following structures are possible? A –&gt; B –&gt; C A &lt;– B &lt;– C A &lt;– B –&gt; C A –&gt; B &lt;– C How do chains, forks, and colliders relate to the concepts of exchangeability and causal effects? Explain in a few sentences. Learning Goals DSEP3: Simulate data from causal graphs under linear and logistic regression structural equation models to check d-separation properties through regression modeling and visualization. Exercises Solutions to these exercises are available on Moodle. Navigate to PollEverywhere for some warm-up exercises. You can download a template RMarkdown file to start from here. In these exercises, you’ll be practicing simulating data from structural equation models and verifying marginal and conditional (in)dependence properties in DAG structures. Always use a regression model as a check. If the situation readily corresponds to a plot, also make a plot as a check. Coding note: When you simulate binary variables and store them in a dataset, it is useful to store them explicitly as categorical as below. (This is most helpful for plotting.) # X is binary. Y and Z are quantitative. sim_data &lt;- data.frame(X = factor(X), Y, Z) Exercise 1 Simulate a chain X -&gt; Y -&gt; Z where all three variables are quantitative. (Use a sample size of 10,000 and a significance level of 0.05 throughout these exercises.) Use appropriate check(s) to verify the conditional relation in this structure. Exercise 2 Simulate a fork X &lt;- Y -&gt; Z where X and Z are quantitative, and Y is binary. Use appropriate check(s) to verify the conditional relation in this structure. Exercise 3 Simulate a collider X -&gt; Y &lt;- Z where Y also has a child A (Y -&gt; A). Let all 4 variables be binary. Use appropriate check(s) to verify the marginal and conditional relations between X and Z in this structure. Exercise 4 Can we extend building block thinking to longer, more complex structures? Let’s investigate here (conceptually, no simulation). Consider the longer structure A &lt;- B &lt;- C -&gt; D. What do you expect about marginal/conditional (in)dependence of A and D? Explain. Consider the longer structure A -&gt; B &lt;- C &lt;- D -&gt; E. What do you expect about marginal/conditional (in)dependence of A and E? Explain. Exercise 5 Discuss the Tweet below with your group. What does Liz Stuart mean by a “stark effect”? What might the trends look like if the effect weren’t so stark? What is the treatment? What evidence does this analysis provide? Is it strong evidence? Do you have any concerns? Wow this is a pretty compelling comparative interrupted time series graph. Don't usually see such a stark effect. https://t.co/VCPLwUrXby — Elizabeth Stuart (@Lizstuartdc) September 6, 2020 Take a few minutes to reflect on today’s ideas by filling out an exit ticket. "],["graphical-structure-of-confounding.html", "Topic 6 Graphical Structure of Confounding Pre-class work Learning Goals Exercises", " Topic 6 Graphical Structure of Confounding Pre-class work Videos/slides Causal and Noncausal Paths: [video], [slides] D-separation: [video], [slides] Checkpoint questions: Link to Moodle checkpoint What is the relationship between d-separation and conditional exchangeability? Explain in a few sentences. Consider the causal graph below with treatment A, outcome Y, and other variables. Which of the following are causal paths? A &lt;– C –&gt; Y A –&gt; Y A –&gt; M –&gt; Y A &lt;– U –&gt; S &lt;– Y Which of the following are noncausal paths? A &lt;– C –&gt; Y A –&gt; Y A –&gt; M –&gt; Y A &lt;– U –&gt; S &lt;– Y Which of the following conditioning sets Z would work to leave causal paths open and block the noncausal paths? \\(Z = \\{C, M, U, S\\}\\) \\(Z = \\{\\}\\) (the empty set (no variables)) \\(Z = \\{C\\}\\) \\(Z = \\{C, M, U\\}\\) \\(Z = \\{C, U\\}\\) \\(Z = \\{C, S\\}\\) Learning Goals CNCP1: Explain how causal and noncausal paths relate to exchangeability and causal effects. DSEP1: Apply d-separation to block noncausal paths in causal DAGs with and without unobserved variables. DSEP2: Apply strategies to deal with exchangeability problems caused by unobserved variables. DSEP3: Simulate data from a causal DAG under linear and logistic regression SEMs to check d-separation properties through regression modeling and visualization. DSEP4: Explain how d-separation relates to conditional exchangeability. Exercises Solutions to these exercises are available on Moodle. Navigate to PollEverywhere for some warm-up exercises. Exercise 1 Let’s draw connections between the graph ideas that we have built up and the core assumption of causal inference: (conditional) exchangeability. Write a few sentences describing the relationship between the following ideas: Causal Markov Assumption/product decomposition Graph building block structures: forks, chains, colliders Causal and noncausal paths (Conditional) exchangeability Exercise 2 For each of the causal graphs below, identify the set of variables needed to achieve conditional exchangeability of the treatment groups \\(A\\) for outcome \\(Y\\) (if possible). Any \\(U\\) variables displayed in the graphs are unobserved/unmeasured. Show your work. Exercise 3 Unmeasured variables are important to think about when constructing causal graphs from expert knowledge. Often times, things like personality traits and social factors (e.g., living situations, communities interacted with). Suppose that in the graphs below, the \\(U\\) variables represents social factors, \\(A\\) represents use of a social service, and \\(Y\\) represents some measure of financial independence. In this context, describe what \\(L\\) might be in each graph and what these graphs illustrate about a general strategy for dealing with exchangeability problems caused by unmeasured variables. Exercise 4 Another way to deal with unmeasured variables is by trying to obtain measurable proxies for them. (Sometimes proxies are also called surrogates.) Broadly speaking, a proxy/surrogate is a variable that is a good indicator for another. The simulation below investigates the use of proxies for achieving conditional exchangeability. Summarize the main findings from these results. library(dplyr) set.seed(451) n &lt;- 10000 C &lt;- rnorm(n, mean = 10, sd = 2) A &lt;- rnorm(n, mean = C, sd = 2) Y &lt;- rnorm(n, mean = C+A, sd = 2) # Proxies (two of them: P1 and P2) P1 &lt;- rnorm(n, mean = C, sd = 1) P2 &lt;- rnorm(n, mean = C, sd = 0.1) sim_data &lt;- data.frame(C, A, Y, P1, P2) lm(Y ~ A+C, data = sim_data) %&gt;% summary() ## ## Call: ## lm(formula = Y ~ A + C, data = sim_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.6410 -1.3500 0.0133 1.3511 7.6709 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.05079 0.10278 0.494 0.621 ## A 1.00020 0.01004 99.643 &lt;2e-16 *** ## C 0.99951 0.01422 70.269 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.006 on 9997 degrees of freedom ## Multiple R-squared: 0.8325, Adjusted R-squared: 0.8324 ## F-statistic: 2.484e+04 on 2 and 9997 DF, p-value: &lt; 2.2e-16 lm(Y ~ A+P1, data = sim_data) %&gt;% summary() ## ## Call: ## lm(formula = Y ~ A + P1, data = sim_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.8180 -1.4517 0.0363 1.4611 9.0563 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.732811 0.101292 17.11 &lt;2e-16 *** ## A 1.164455 0.009892 117.71 &lt;2e-16 *** ## P1 0.668516 0.012527 53.37 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.163 on 9997 degrees of freedom ## Multiple R-squared: 0.8052, Adjusted R-squared: 0.8052 ## F-statistic: 2.066e+04 on 2 and 9997 DF, p-value: &lt; 2.2e-16 lm(Y ~ A+P2, data = sim_data) %&gt;% summary() ## ## Call: ## lm(formula = Y ~ A + P2, data = sim_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.4902 -1.3604 0.0146 1.3524 7.5656 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.06553 0.10271 0.638 0.523 ## A 1.00173 0.01003 99.873 &lt;2e-16 *** ## P2 0.99653 0.01420 70.189 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.006 on 9997 degrees of freedom ## Multiple R-squared: 0.8323, Adjusted R-squared: 0.8323 ## F-statistic: 2.481e+04 on 2 and 9997 DF, p-value: &lt; 2.2e-16 Exercise 5 Historically, people have tried to create definitions for confounders by listing criteria that purely rely on associations. For example: A confounder must: 1. Be associated with treatment and outcome 2. Not be caused by treatment Using the causal graph below, explain why this is not a good definition for a confounder. How are things going? What’s on your mind? Take a few minutes to reflect on today’s ideas by filling out an exit ticket. "],["graphical-structure-of-selection-bias.html", "Topic 7 Graphical Structure of Selection Bias Pre-class work Learning Goals Exercises", " Topic 7 Graphical Structure of Selection Bias Pre-class work Required reading WHATIF: 8.1 - 8.3 Learning Goals CNCP1: Explain how causal and noncausal paths relate to exchangeability and causal effects. DSEP1: Apply d-separation to block noncausal paths in causal DAGs with and without unobserved variables. DSEP2: Apply strategies to deal with exchangeability problems caused by unobserved variables. DSEP3: Simulate data from a causal DAG under linear and logistic regression SEMs to check d-separation properties through regression modeling and visualization. DSEP4: Explain how d-separation relates to conditional exchangeability. Exercises Solutions to these exercises are available on Moodle. Navigate to PollEverywhere for some warm-up exercises. Navigate to DAGitty and click the “Launch online” link. Exercise 1 In epidemiology, a common study design is known as a case-control study, which are used to understand associations between diseases and risk factors. In these studies, we identify people with disease (cases) and without disease (controls) are collect information on risk factors/exposures of interest. A 1981 case-control study looked at the relationship between coffee drinking and pancreatic cancer. Cases were hospital patients with histologically confirmed pancreatic cancer. To select controls, researchers asked the physicians caring for the cases to refer patients without pancreatic cancer. Draw a causal graph to represent the situation and explain how selection bias could arise via noncausal path(s). Exercise 2 For each of the causal graphs below, identify the set of variables needed to achieve conditional exchangeability of the treatment \\(A\\) and outcome \\(Y\\). Check your answers to one of the graphs using DAGitty. Exercise 3 In this exercise, we’ll consider how causal graphs can inform study design. In the 1970s, researchers noticed a consistent association between estrogen use and endometrial cancer. Groups debated two hypotheses: Estrogens do cause cancer. Estrogens don’t cause cancer but lead to uterine bleeding, leading to more frequent doctor visits, leading to increased diagnosis of existing cancer. The following study plan was proposed: restrict the study only to those with uterine bleeding and compare cancer rates in estrogen-users and non-users. In this way, all participants have the same chance of being diagnosed. The following causal graphs correspond to the two hypotheses: (The graphs don’t show confounders of the estrogens-endometrial cancer relationship for compactness. We can assume that these have already been adjusted for.) Part a Consider the study proposal above: restrict analysis to those with uterine bleeding. Under the graphs for the two hypotheses, will estrogens and diagnosed cancer be associated? Can this study proposal distinguish between the two hypotheses? Part b Consider another study proposal: ensure that everyone is screened frequently, and we don’t restrict our analysis to only those with uterine bleeding. What arrow (in either DAG 1 or 2) can be removed as a result of this study design? Can this study proposal distinguish between the two hypotheses? What are you looking forward to this weekend? Take a few minutes to reflect on today’s ideas by filling out an exit ticket. "],["digestion-study-designs-and-graphs.html", "Topic 8 Digestion: Study Designs and Graphs Goals Your Task Grading", " Topic 8 Digestion: Study Designs and Graphs Goals Today we’ll take time to synthesize ideas in contexts that you’ve identified as meaningful. DESI2: Explain how quasi-experimental and general observational studies relate to exchangeability. DESI3: Compare the strengths and weaknesses of different study designs for answering a research question. 1/Juneteenth is a good reason for a #causalinference reminder: It ain't race but racism.To change society, focus on well-defined interventions. Studies of “Whites vs. Blacks” document the existence of serious problems, but don't propose solutions.https://t.co/uzzHYS8gdO pic.twitter.com/cuiEYqrDGx — Miguel Hernán (@_MiguelHernan) June 19, 2020 Your Task Identify one context from the selection below that are of interest to the group. (These come from media items that you have shared on Slack. Also feel free to discuss something not listed below.) How are college towns affected by COVID-19? What inequities are present in bail decisions? What can we do to prevent wildfires? What financial policies can help businesses in pandemic times? How does climate change affect port industries? What are the consequences of reallocating funding for the police? Who cares for our caregivers? Do remedial programs help with student achievement? Discuss the following with each other, and record your responses in a well-organized shared document: What treatment(s) might be of interest in this context? Is this treatment something that could realistically be intervened upon? What quasi-experimental study design do you think would be most ideal for studying the causal effect of the treatment? Describe how you would implement the design. Use a causal graph to think through whether or not marginal or conditional exchangeability holds in your setting. Feel free to use DAGitty. Record your conclusions. Do you think that a general observational study would be feasible/appropriate in this setting? Do you think an overall average causal effect or causal effects within subgroups would be more of interest? Does the answer to that depend on who is using the study results? Who might suffer based on the results of this causal analysis and the ways in which the results are communicated? Share the document with me by Wednesday, September 16: If it is a Google Docs, add me so that I have commenting privileges. Otherwise, email me a copy. Grading Everyone in the group will receive the same grade for the DESI2 and DESI3 objectives. This will count towards mastery requirements. "],["the-smoking-birth-weight-paradox.html", "Topic 9 The Smoking-Birth Weight Paradox Pre-class work Learning Goals Background Discussion", " Topic 9 The Smoking-Birth Weight Paradox Pre-class work Readings The Birth Weight “Paradox” Uncovered? Checkpoint Learning Goals CNCP1: Explain how causal and noncausal paths relate to exchangeability and causal effects. DSEP1: Apply d-separation to block noncausal paths in causal DAGs with and without unobserved variables. DSEP2: Apply strategies to deal with exchangeability problems caused by unobserved variables. DSEP4: Explain how d-separation relates to conditional exchangeability. Background To facilitate our discussion, key pieces of information and terminology from the article are summarized below. Crude mortality rate ratio \\[\\frac{\\hbox{Infant mortality rate for maternal smokers}}{\\hbox{Infant mortality rate for maternal non-smokers}} = 1.55\\] Adjusted mortality rate ratio: same ratio but arising from a regression model in which birth weight was held constant. This was 1.09. Stratum-specific mortality rate ratios In low birth weight infants: \\[\\frac{\\hbox{Infant mortality rate for maternal smokers}}{\\hbox{Infant mortality rate for maternal non-smokers}} = 0.79\\] In normal birth weight infants: \\[\\frac{\\hbox{Infant mortality rate for maternal smokers}}{\\hbox{Infant mortality rate for maternal non-smokers}} = 1.80\\] Discussion Discuss responses to the questions below with your group. You have the option of making a writeup of this discussion a component of your final project. (But it doesn’t have to be. There will be several options for the project.) Main questions In all causal diagrams considered in this paper, no confounders of maternal smoking and mortality are shown. Given the intent of the paper, do you think this is a problem? Explain. Comment on the choice and sequencing of causal diagrams presented in the paper. If the authors were writing for people who are new to causal graphs, do you think that the authors effectively presented essential graph ideas? Figure 3.7 is the most realistic causal graph presented. Analyze this graph using d-separation to explain why conditioning on low birth weight leads to problems. We actually need to dig a little deeper to fully explain the paradox. The mere existence of an open noncausal does not fully explain it. We need to incorporate knowledge about the effect directions and relative effect magnitudes along key arrows. Low birth weight types A and B clearly have positive relationships with LBW. Clearly explain the nature of the conditional relationship that arises when conditioning on LBW. What is likely true about the relative magnitude of the Smoking –&gt; Mortality effect and the U –&gt; Mortality effect in order to explain the paradoxical association that infants of maternal smokers are specifically protected as compared to infants of maternal nonsmokers. Explain. In our discussions so far, we’ve conditioned on Low birth weight = Yes. Do you think the paradox would hold if we condition on Low birth weight = No? Explain in terms of d-separation ideas. Digging deeper Explain the alcoholism-liver cancer example at the end of the paper. Could smoking protect against COVID-19 infection? Read this Tweet thread, and use d-separation ideas to explain the surprising finding discussed at the start of the thread. There’s a new paper circulating today about “risk factors” for COVID19 which is getting misinterpreted in a pretty common way: applying conclusions about causation to results obtained via methods designed only for finding correlations.It’s time for a #tweetorial! pic.twitter.com/8rymWtGW9l — Ellie Murray (@EpiEllie) May 8, 2020 "],["applied-analysis-regression.html", "Topic 10 Applied Analysis: Regression Pre-class work Learning Goals Context Analysis", " Topic 10 Applied Analysis: Regression Pre-class work Videos/slides Asking Clear Questions and Building Graphs: [video], [slides] Estimating Causal Effects: Regression: [video], [slides] Checkpoint Learning Goals REGR1: Conduct and interpret results from an appropriate regression analysis to estimate causal effects and effect modification of causal effects. Navigate to PollEverywhere for some warm-up exercises. Context Marijuana decriminalization is a major part of the dialogue on mass incarceration because marijuana-related offenses form a large part of drug offenses. In considering decriminalization, it is important to also think through other consequences of marijuana use. In this analysis, we will be interested in the following: How does adolescent marijuana smoking affect the risk of adulthood cigarette smoking? We’ll explore this question by looking at data from the Add Health study (https://cpc.unc.edu/projects/addhealth), a national survey of adolescent health. The following variables are in the dataset: exposure: Indicator for whether or not marijuana was smoked in adolescence. 1=yes, 0=no. (Treatment) smoke: Indicator for whether the individual smoked in adulthood. 1=yes, 0=no. (Outcome) age: Age at study entry male: Indicator for whether the individual was male. 1=yes, 0=no. white: Indicator for whether the individual was White. 1=yes, 0=no. susp: Indicator for whether the individual was ever suspended from school. 1=yes, 0=no. mathG: Math grade (1 to 4 corresponding respectively to A to D) readG: Reading grade (1 to 4 corresponding respectively to A to D) parentED: Parent education (1 to 5 corresponding respectively to less than high school, high school, vocational school, some college, and college graduate and beyond). housesmoke: Indicator for the presence of a cigarette smoker in the individual’s household. 1=yes, 0=no. Nonresponse bias is a ubiquitous source of concern for surveys. Add Health investigators studied determinants of nonresponse and found that living in a rural neighborhood and being white decreased chances of responding. They found that college education or higher in parents and parental involvement in school fundraising increased the chances of responding. (In case you’re interested, their report on nonresponse is available here.) Analysis A template RMarkdown document that you can start from is available here. You can read in the dataset as below: addhealth &lt;- readr::read_csv(&quot;https://www.dropbox.com/s/h09nq0nwgx8eioz/addhealth.csv?dl=1&quot;) Note that all variables are encoded as numeric. You may need to use factor(variable) when making certain visualizations. Part 1: Causal graph construction Construct an appropriate causal graph based on your contextual knowledge. Use DAGitty to collaborate with your group members. The graph should contain unmeasured variables and variables in the dataset (but not necessarily all of them). Insert a picture of your final graph. You can insert images in Markdown with: ![](graph_filename.png) In at most 400 words, discuss the impact of unobserved variables (come up with at least one) and selection bias. Based on your graph, can you achieve conditional exchangeability in this analysis? If not, what variables would you like to have measured? Incorporate the concepts of causal and noncausal paths and d-separation in your discussion. Even if you don’t believe conditional exchangeability holds, still proceed with the analysis. You will acknowledge limitations at the end of your write-up. Part 2: Exploratory analysis Construct visualizations to inform the building of an appropriate model for estimating the following average causal effects: Overall average causal effect Average causal effects within subgroups defined by one variable of your choice Your visualizations should: Explore nonlinearity if appropriate Explore interactions between the treatment variable and two other variables (interactions between treatment and each of two other variables - not a 3-way interaction). Use this to inform your choice of subgroup variable in estimating subgroup-causal effects. In case it’s relevant, the code below adds logistic regression smoothing lines to ggplot2 figures: ggplot(data, aes(x = X, y = y)) + geom_point() + geom_smooth(se = FALSE, color = &quot;blue&quot;) + geom_smooth(formula = y~ns(x,2), method = &quot;glm&quot;, method.args = list(family=&quot;binomial&quot;), se = FALSE, color = &quot;red&quot; ) Part 3: Modeling Fit a model to estimate the overall average causal effect. Fit a model to estimate the subgroup average causal effects (for one subgroup variable). For both models, display the summarized output table and 95% confidence intervals for the coefficients. Part 4: Discussion In this last part of the write-up, you’ll interpret modeling results and discuss limitations. (Limit this part to 500 words.) Interpret the coefficient(s) of causal interest on an appropriate scale for both models. Include a warning for the reader about interpreting all coefficients causally, and provide a brief explanation. Using both the confidence intervals and effect magnitudes, discuss the results of your analysis in a contextually meaningful way for potential consumers of your results. (Pick a reasonable target audience, and address your writing to those types of people.) Discuss limitations of your analysis in terms of exchangeability and generalizability. "],["inverse-probability-weighting.html", "Topic 11 Inverse Probability Weighting Pre-class work Learning Goals Exercises", " Topic 11 Inverse Probability Weighting Pre-class work Videos/slides Estimating Causal Effects: Inverse Probability Weighting: [video], [slides] Checkpoint Learning Goals Verify properties of inverse probability weighting for estimating average causal effects using simulation Exercises Solutions to these exercises are available on Moodle. Navigate to PollEverywhere for some warm-up exercises. You can download a template RMarkdown file to start from here. Exercise 1: Simulate Simulate data from the causal graph below where \\(Z\\), \\(W\\), and \\(A\\) are binary, and \\(Y\\) is quantitative. Use the model below for your structural equation for \\(A\\), and store your data in a dataset object called sim_data. \\[ \\log(\\mathrm{odds}(A = 1)) = -1 + 0.4 Z + 0.4 W + 0.9 Z*W \\] Exercise 2: Intervene Based on your SEM, what do you expect to be the average causal effect? Modify your simulation to simulate an intervention where all are treated and all are untreated to verify that this is the true average causal effect. Exercise 3: Inverse probability weighting Here, we’ll check the performance of inverse probability weighting for estimating the average causal effect. In practice, we don’t know the true SEM underlying the data, so we need to estimate the appropriate weights from the data. This starts from estimating the probability of receiving treatment conditional on appropriate variables. (This probability is called the propensity score.) Fit an appropriate propensity score model called ps_mod. The code below uses your fitted ps_mod to compute IP weights. Look up the mutate() and case_when() functions from dplyr by entering ?function_name in the Console. predict(logistic_mod, newdata = data_to_make_predictions_for, type = \"response\") is used to predict probabilities from a logistic regression model. (Without type = \"response\", log-odds are computed.) Add comments to this code to document these different pieces, and check in with the instructor if you have questions. sim_data &lt;- sim_data %&gt;% mutate( ps = predict(ps_mod, newdata = sim_data, type = &quot;response&quot;), ip_weight = case_when( A==1 ~ 1/ps, A==0 ~ 1/(1-ps) ) ) Fit an ordinary regression model Y ~ A that ignores the IP weights. Is the estimated ACE what you expected? Incorporate the IP weights into your analysis by modifying your model from part c as below. Is the estimated ACE what you expected? lm(..., data = ..., weights = ip_weight) Note: Using weights = ... in glm(..., family = \"binomial\") does not work exactly the way we want it to. (It works as we want for lm().) Going forward, we will use a specialized package (the survey package) for dealing with weights. Exercise 4: Balance checking What is the key differentiator between regression and inverse probability weighting? Let’s verify that unique property of IP weighting. Make plots to show the relationship between \\(Z\\) and \\(A\\) and between \\(W\\) and \\(A\\) in the original, unweighted data. Modify your plot to incorporate the IP weights by adding the following to aes(). What property of IP weighting does this show? aes(..., weight = ip_weight) Extra! If you’ve taken Statistical Machine Learning, what connections can you make between ideas about predictive modeling and propensity score estimation? If you haven’t taken that course but are curious, feel free to ask the instructor! Take a few minutes to reflect on today’s ideas by filling out an exit ticket. "],["applied-analysis-inverse-probability-weighting.html", "Topic 12 Applied Analysis: Inverse Probability Weighting Pre-class work Learning Goals Analysis", " Topic 12 Applied Analysis: Inverse Probability Weighting Pre-class work Required reading WHATIF: 12.1, 12.2, 12.4 Checkpoint Learning Goals IPTW1: Conduct and interpret results from an appropriate IPW analysis to estimate causal effects and effect modification of causal effects. Navigate to PollEverywhere for some warm-up exercises. Analysis You can download a template RMarkdown file to start from here. We’ll be looking at the dataset explored in our WHATIF book to answer the question: How does smoking cessation affect weight gain? The data are available in the cidata package. Install this package (you may need to install the remotes package first): remotes::install_github(&quot;malcolmbarrett/cidata&quot;) Our data come from the National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study (NHEFS). We will use the nhefs_complete dataset which has removed cases with missing data for some key variables. More information is available via ?nhefs_complete. The variable codebook is available as nhefs_codebook. library(survey) # You may need to install the survey package library(dplyr) library(ggplot2) library(splines) library(cidata) data(nhefs_complete) # Load the data View(nhefs_codebook) # Look at the variable codebook Part 1: Causal graph analysis Use the causal graph below as a starting point for the analysis. The selection node S indicates those for whom we have complete data. The treatment variable is qsmk, and the outcome variable is wt82_71. If this is the true causal graph underlying the data, can we achieve conditional exchangeability? Show your work fully. Part 2: Propensity score modeling Based on your causal graph analysis, fit an appropriate propensity score model. Use visualizations to inform the construction of your model. Accompany each visualization with a brief description of what it helps you decide. Use your model to compute appropriate weights, and add these weights to the dataset. Use “before and after” visualizations to compare balance of key variables before and after weighting. Write a few sentences summarizing your conclusions from this stage. The code below adds logistic regression smoothing lines to ggplot2 figures: ggplot(data, aes(x = X, y = y)) + geom_point() + geom_smooth(se = FALSE, color = &quot;blue&quot;) + geom_smooth(formula = y~ns(x,2), method = &quot;glm&quot;, method.args = list(family=&quot;binomial&quot;), se = FALSE, color = &quot;red&quot; ) The (incomplete) code below is useful for computing appropriate weights: your_data &lt;- your_data %&gt;% mutate( ps = predict(ps_mod, newdata = your_data, type = &quot;response&quot;), ip_weight = case_when( A==1 ~ ???, A==0 ~ ??? ) ) You can incorporate weights into most ggplot2 figures by adding weight to the aesthetics: aes(..., weight = ip_weight) Part 3: Modeling with IP weights Assuming that you have added the ip_weight variable to the nhefs_complete dataset, the code below fits the model \\[ E[Y^a] = \\beta_0 + \\beta_1a \\] (As discussed in 12.4 of WHATIF, this model is called a marginal structural model (MSM).) # Set up information about weights design &lt;- svydesign(ids = ~0, weights = nhefs_complete$ip_weight, data = nhefs_complete) msm_fit &lt;- svyglm( wt82_71 ~ qsmk, data = data, design = design ) summary(msm_fit) confint(msm_fit) Fit a marginal structural model to estimate the overall average causal effect. Construct a visualization to explore if the causal effect of smoking cessation might differ by prior smoking intensity (smokeintensity). Briefly interpret your visualization. Fit a model to estimate how the average causal effect differs across smoking intensity. (Adapt the svyglm() formula in the same way you would for lm().) Using both the confidence intervals and effect magnitudes, discuss the results of your analysis in a contextually meaningful way. "],["time-varying-treatments.html", "Topic 13 Time-Varying Treatments Pre-class work Learning Goals Exercises", " Topic 13 Time-Varying Treatments Pre-class work Required reading WHATIF: 19.1 - 19.4 Checkpoint Learning Goals TVTR1: Formulate research questions that can be answered in a time-varying treatment setting TVTR2: Explain why regression does not generally work in time-varying settings with treatment-confounder feedback using d-separation ideas Exercises Solutions to these exercises are available on Moodle. Exercise 1 Which of these graphs could represent a sequentially randomized experiment and why? (Graphs that could represent sequentially randomized experiments indicate the presence of sequential exchangeability.) Exercise 2 Treatment-confounder feedback is the situation where past treatment \\(A_{t-1}\\) affects the value of future confounders \\(L_{t}\\). The graph below represents the fundamental part of Graph 2 from Exercise 1 that allows us to explore the impact of treatment-confounder feedback. Using d-separation ideas, explain why a regression model of the form \\(E[Y \\mid A_0, A_1, L_1]\\) creates a problem for estimating the effect of a treatment strategy for \\(A_0\\) and \\(A_1\\). How would you expect this graph to change under inverse probability weighting? Thus explain why IPW allows us to estimate the effect of a treatment strategy for \\(A_0\\) and \\(A_1\\). More generally, treatment-confounder feedback has been used to describe not only direct connections between past treatment and future confounders, but also any open path between them. Expanding on the graph here, what other structures lead to problems for conditioning-based estimation methods? "],["sensitivity-analyses-for-unmeasured-variables.html", "Topic 14 Sensitivity Analyses for Unmeasured Variables Pre-class work Learning Goals Background Exercises", " Topic 14 Sensitivity Analyses for Unmeasured Variables Pre-class work Videos/slides Sensitivity Analyses for Unmeasured Variables: [video], [slides] Checkpoint Learning Goals SENS1: Evaluate the sensitivity of findings to data quality and propose appropriate sensitivity analyses for a research investigation. SENS2: Conduct and communicate the results of a sensitivity analysis for unmeasured confounding. Background We will be implementing the approach for a sensitivity analysis proposed in the research article Assessing Sensitivity to Unmeasured Confounding Using a Simulated Potential Confounder by Carnegie, Harada, and Hill. It looks like their package treatSens was taken off CRAN and is undergoing revisions. We will implement their approach for a sensitivity analysis for the particular case of quantitative treatment, outcome, and unmeasured confounder. Summary of approach: Identify set of variables \\(Z\\) that results in conditional exchangeability of the treatment groups. Express the joint distribution of the data as below, with the assumption that \\(U\\) and \\(Z\\) are independent. \\[ \\begin{align*} P(Y, A, U \\mid Z) &amp;= P_1(Y \\mid A, U, Z) P_2(A \\mid U, Z) P_3(U \\mid Z) \\\\ &amp;= P_1(Y \\mid A, U, Z) P_2(A \\mid U, Z) P_3(U) \\end{align*} \\] Express these components of the joint distribution as structural equations: \\[ Y \\sim N(\\beta_0 + \\beta_1 A + \\beta_2 Z + \\beta_3 U, \\sigma_Y^2) \\] \\[ A \\sim N(\\alpha_0 + \\alpha_1 Z + \\alpha_2 U, \\sigma_A^2) \\] \\[ U \\sim N(0, \\sigma_U^2) \\] Using probability theory, we can rewrite the joint distribution to express \\(U\\) as a function of \\(A\\) and \\(Y\\) (see paper). These formulas require the residuals and estimated standard deviation of residuals from the following models: Y ~ A+Z A ~ Z Key idea: We can use observed data simulate \\(U\\) such that it is consistent with the above structural equations. Sensitivity parameters: \\(\\beta_3\\) and \\(\\alpha_2\\). In our code below, we will call these assoc_Y and assoc_A respectively. Exercises You can download a template RMarkdown file to start from here. Warm-up Work to understand what the code below is doing. Clarify with the instructor as needed. You will be adapting this code to implement a sensitivity analysis in the context of the smoking-weight gain study that we’ve explored previously. library(dplyr) library(ggplot2) sensitivity_analysis &lt;- function(.data, model_A, model_Y, assoc_A, assoc_Y) { n &lt;- nrow(.data) # Obtain residuals with residuals() # Obtain residual variances with sigma() res_A &lt;- residuals(model_A) res_var_A &lt;- sigma(model_A)^2 res_Y &lt;- residuals(model_Y) res_var_Y &lt;- sigma(model_Y)^2 # Compute the mean and variance of U given A and Y mean_U_term1 &lt;- (assoc_A/res_var_A)*res_A mean_U_term2 &lt;- (((res_var_A - assoc_A^2)*assoc_Y)/(res_var_A*res_var_Y))*res_Y mean_U &lt;- mean_U_term1 + mean_U_term2 var_U_term1 &lt;- (res_var_A - assoc_A^2)/(res_var_A*res_var_Y) var_U_term2 &lt;- res_var_Y - assoc_Y^2 + ((assoc_A*assoc_Y)^2)/res_var_A var_U &lt;- var_U_term1*var_U_term2 # Simulate U and add it to the data U &lt;- rnorm(n, mean = mean_U, sd = sqrt(var_U)) .data$U &lt;- U ######################################################################## # The part below is the only part you need to change to implement # the sensitivity analysis in a new context. # Refit model to estimate the causal effect updated_model &lt;- lm(Y ~ A+C+U, data = .data) # The names of the coefficients and confidence interval output rows # are called &quot;A&quot; for the treatment variable A. # This will change in a new dataset. list(c( estimate = unname(coefficients(updated_model)[&quot;A&quot;]), ci_95_lower = confint(updated_model)[&quot;A&quot;,1], ci_95_upper = confint(updated_model)[&quot;A&quot;,2] )) } # Set up simulated example data set.seed(451) n &lt;- 10000 U &lt;- rnorm(n, 10, 1) C &lt;- rnorm(n, 10, 1) A &lt;- rnorm(n, 2+C+U, 2) Y &lt;- rnorm(n, 10 + A + C + U, 10) sim_data &lt;- data.frame(U, C, A, Y) # Begin the sensitivity analysis # Fit required models for the sensitivity analysis mod_A &lt;- lm(A ~ C, data = sim_data) mod_Y &lt;- lm(Y ~ A+C, data = sim_data) # Set up degree of association between U and A and between U and Y # The U-&gt;A associations have some constraints: we set up values # for the U-&gt;A associations that are at most equal to the # standard deviation of the residuals from the model for A. U_A_assocs &lt;- seq(from = 0.01, to = sigma(mod_A), length.out = 10) U_Y_assocs &lt;- seq(from = 0.5, to = 5, by = 0.5) # Form all combinations of the U-&gt;A and U-&gt;Y sensitivity parameters sens_data &lt;- expand.grid(U_A = U_A_assocs, U_Y = U_Y_assocs) # Run sensitivity analysis sens_data &lt;- sens_data %&gt;% group_by(U_A, U_Y) %&gt;% mutate(sens = sensitivity_analysis(sim_data, mod_A, mod_Y, U_A, U_Y)) # Collect sensitivity analysis results in a data.frame sens_data &lt;- bind_cols(sens_data[,1:2], bind_rows(sens_data$sens)) # Plot results prepender &lt;- function(string, prefix = &quot;U -&gt; Y strength:&quot;) paste(prefix, string) ggplot(sens_data, aes(x = U_A, y = estimate)) + geom_ribbon(aes(ymin = ci_95_lower, ymax = ci_95_upper), fill = &quot;grey70&quot;) + geom_line() + geom_hline(aes(yintercept = coefficients(mod_Y)[&quot;A&quot;]), color = &quot;blue&quot;, lty = &quot;dashed&quot;) + geom_hline(aes(yintercept = 0), color = &quot;black&quot;) + facet_wrap(~U_Y, labeller = as_labeller(prepender)) + labs(x = &quot;Strength of U -&gt; A association&quot;, y = &quot;ACE and 95% CI&quot;) Main exercise Here, we will adapt the code above to implement a sensitivity analysis for unmeasured confounding for the smoking-weight gain study. The treatment variable is smkintensity82_71 the change in number of cigarettes smoked per day from 1971 to 1982. Assume that a graphical analysis has led to the conclusion that conditional exchangeability holds given smokeyrs, age, and asthma. Display graphical output from the sensitivity analysis and write a brief discussion of conclusions you can make from the sensitivity analysis (no more than 400 words). # Load data library(cidata) data(nhefs_complete) # View the data codebook View(nhefs_codebook) "],["causal-discovery.html", "Topic 15 Causal Discovery Pre-class work Learning Goals Exercises", " Topic 15 Causal Discovery Pre-class work Videos/slides Causal Discovery: [video], [slides] Checkpoint Learning Goals DISC1: Demonstrate conceptual understanding of causal discovery by reasoning about outputs of the process and by manually conducting it using regression models. DISC2: Use output from causal discovery to enhance a causal analysis as part of a sensitivity analysis. Exercises You can download a template RMarkdown file to start from here. Exercise 1 There are two genes (Gene A and Gene B) that produce Protein X. Gene A is the primary producer. Whenever Gene A is functional, Gene B is inactive and produces nothing. However, if Gene A loses function, Gene B becomes active and produces Protein X in Gene A’s place in exactly the same amounts. Draw the DAG implied by this expert knowledge. We can view Gene A as a binary variable with values “functional” and “non-functional”. Will Gene A and Protein X be marginally independent or marginally dependent in the data? Explain. Discuss your answers to (a) and (b) in the context of a relevant concept. Exercise 2 In this exercise, we’ll think about the conditional independence test and the role of the hypothesis testing significance level as a tuning parameter. As the significance level is lowered to 0, what would you expect to happen to the graph skeleton learned by causal discovery algorithms? As the significance level is increased to 1? Explain. Exercise 3 Consider data that truly come from a chain X -&gt; Y -&gt; Z. What pattern would a causal discovery algorithm report? It is possible to supply causal discovery algorithms with prior knowledge - for example, specific edges that are required to be present. If you could supply prior knowledge to the algorithm on only one edge that is required to be present, what edge (if any) would allow the entire structure to be learned? Explain briefly. Exercise 4 Consider data that truly come from a fork X &lt;- Y -&gt; Z. What pattern would a causal discovery algorithm report? If you could supply prior knowledge to the algorithm on only one edge that is required to be present, what edge (if any) would allow the entire structure to be learned? Explain briefly. Exercise 5 We have learned the following structure from the skeleton building phase. We have the following results from conditional independence tests (\\(H_0\\) indicates conditional independence, significance level = 0.01): \\(X \\perp\\!\\!\\!\\perp Z \\mid Y\\)? p-value = 0.001 \\(X \\perp\\!\\!\\!\\perp W \\mid Y\\)? p-value = 0.1 \\(Y \\perp\\!\\!\\!\\perp V \\mid W\\)? p-value = 0.1 \\(U \\perp\\!\\!\\!\\perp W \\mid V\\)? p-value = 0.1 What pattern would a causal discovery algorithm report? Show your work. Exercise 6 We have measured 3 variables \\(X\\), \\(Y\\), and \\(Z\\) (all quantitative). You can read in the data below. disc_data &lt;- readr::read_csv(&quot;https://www.dropbox.com/s/moj3k3fed7puicr/discovery_data.csv?dl=1&quot;) Step through the causal discovery process, using regression models as your conditional independence test. Use a type 1 error rate (significance level) of \\(\\alpha=0.01\\). Show all work. This involves: Showing model output. Writing a sentence using numbers from the output at each step to show the decisions made by the algorithm. Report the final output that the discovery algorithm would give. Exercise 7 Clearly describe how causal discovery could be used as a sensitivity analysis for a regression or IP weighting analysis for estimating causal effects. "],["homework-1.html", "Homework 1 Exercise 1 Exercise 2 Exercise 3 Exercise 4 Exercise 5", " Homework 1 Due Sunday, September 6 at midnight CST on Moodle Please turn in a single document containing your responses. Exercise 1 Consider the 4 scenarios below. For all scenarios, \\(A\\) represents a binary treatment, and \\(Y\\) represents the observed outcome (quantitative). Marginal exchangeability, independence of \\(Y\\) and \\(A\\) Marginal exchangeability, dependence of \\(Y\\) and \\(A\\) Lack of marginal exchangeability, independence of \\(Y\\) and \\(A\\) Lack of marginal exchangeability, dependence of \\(Y\\) and \\(A\\) Draw plots that illustrate the following 4 scenarios. Annotate the plots sufficiently enough to clearly show the properties indicated in the scenarios. Alternatively, you can create numerical examples. Clearly show how the numerical examples show the properties in the scenarios. Based on your illustrations, provide clarification to a colleague who asks you the following: “If marginal exchangeability holds, then treatment and outcome are independent right? So doesn’t that always mean that there will never be a causal effect? Because a causal effect means that outcome depends on treatment?” Exercise 2 When, if ever, is a direct comparison of the observed outcomes in the treated and untreated a good estimate of an average causal effect? Explain your answer with relevant discussion of exchangeability and study designs. Exercise 3 The table below shows data on a binary outcome \\(A\\), a binary covariate \\(Z\\), and a quantitative outcome \\(Y\\). \\(Z\\) \\(A\\) \\(Y\\) A 1 40 A 1 40 A 1 40 A 1 40 B 1 20 B 1 20 A 0 30 A 0 30 B 0 10 B 0 10 B 0 10 B 0 10 Assuming that the treatment groups are exchangeable conditional on \\(Z\\), estimate the average causal effect \\(E[Y^{a=1}-Y^{a=0}]\\). Suppose that the treatment groups are still exchangeable conditional on \\(Z\\). Are they marginally exchangeable? Show and explain your work. Exercise 4 To what extent do you agree with the following statement? “Instrumental variables, regression discontinuity, and interrupted time series designs are essentially randomized experiments.” To fully explain any points of agreement and/or disagreement, your response should discuss exchangeability and communicate how the mentioned designs work. Exercise 5 Suppose that you are designing a general observational study to study the effect of weekly practice of yoga on stress levels. What variables would you like to collect to achieve conditional exchangeability? Explain how these variables could contribute to a lack of exchangeability. Which quasi-experimental design (of the 3 that we’ve discussed) do you think would be most practical/feasible to use to study the effect of yoga practice on stress? Justify your answer. Which quasi-experimental design do you think is most ideal for this study in terms of achieving exchangeability? Justify your answer. "],["homework-2.html", "Homework 2 Introduction Exercise 1 Exercise 2 Exercise 3 Exercise 4 Exercise 5 Exercise 6 Exercise 7 Exercise 8 Exercise 9", " Homework 2 Due Sunday, September 13 at midnight CST on Moodle Please turn in a single knitted PDF document containing your responses. (If you have LaTeX installed, you can knit directly to PDF (preferred method). Otherwise, you can knit to HTML and “Print” the page to save it as a PDF.) A template that you can work from is available here. Please save this file as hw2_LastName_FirstName.Rmd. Introduction The context of the exercises in this assignment comes from the study A Population-Based Study on Nighttime Road Traffic Noise and Insomnia published in the journal Sleep in 2017. The article is freely available here. You will need to read parts of this article for this assignment. The following learning objectives are covered in this assignment: EXCH1: Apply the concepts of marginal and conditional exchangeability to answer questions about (hypothetical) data on potential outcomes. EXCH2: Give examples of when marginal and conditional exchangeability would and would not hold in various data contexts. EXCH3: Explain why a direct comparison of the outcomes in the treated and untreated is misleading as an estimate of a causal effect. DESI1: Explain how randomized experiments relate to exchangeability. DESI2: Explain how quasi-experimental and general observational studies relate to exchangeability. DESI3: Compare the strengths and weaknesses of different study designs for answering a research question. PGRA1: Apply the Causal Markov assumption to express the joint distribution of data. CNCP1: Explain how causal and noncausal paths relate to exchangeability and causal effects. DSEP1: Apply d-separation to block noncausal paths in causal DAGs with and without unobserved variables. DSEP2: Apply strategies to deal with exchangeability problems caused by unobserved variables. DSEP3: Simulate data from a causal DAG under linear and logistic regression SEMs to check d-separation properties through regression modeling and visualization. DSEP4: Explain how d-separation relates to conditional exchangeability. SENS1: Evaluate the sensitivity of findings to data quality and propose appropriate sensitivity analyses for a research investigation Exercise 1 In judging the strength of evidence in research studies, it is important to critically evaluate the quality of data that the authors used. Read the Noise Exposure Assessment section of the paper. Briefly explain 2 concerns that you have about how the authors determined noise levels. (4 sentences max.) Exercise 2 Figure 1 shows (a simplified version of) the causal graph the authors used in their work. Write down the joint distribution of the data using the Causal Markov Assumption. Use the variable abbreviations below: D: Demography CD: Chronic diseases L: Lifestyle SES: Socioeconomic status NS: Noise sensitivity NA: Noise annoyance A: Road traffic noise Y: Sleep disturbances Exercise 3 In Figure 1, which parts of the graph generate causal effects of the treatment (road traffic noise) on the outcome (sleep disturbances)? State these explicitly. (No explanation required.) Are the observed outcomes across treatment levels a good representation of the missing potential outcomes? Which parts of the graph are relevant to look at to answer that question? (Describe this in general terms rather than stating all of them.) How do these parts of the graph create misleading associations? Explain in terms of relevant graph building block structures and exchangeability. (4 sentences max.) Exercise 4 Consider a modified version of the Figure 1 graph shown below. How can you identify a set of variables \\(Z\\) that will result in conditional exchangeability of the treatment groups? Briefly explain how your proposed process achieves this. (4 sentences max.) Identify one possible set \\(Z\\). Show your work. Exercise 5 Here, you’ll check if the set \\(Z\\) you identified in Exercise 4 works. Simulate data from a causal graph that has the same structure as the graph in Exercise 4. All variables should be quantitative except for the outcome \\(Y\\), which should be binary. Display output from an appropriate check. Exercise 6 Continuing from the causal graph in Exercise 4, suppose that the household income and physical activity variables were unmeasured. Use two different strategies to try to regain conditional exchangeability (at least approximately). (4 sentences max.) Exercise 7 What would the causal graph from Exercise 4 look like if this study had been a randomized experiment? You can draw the graph or explain how it would look different. Using this graph, make a connection between relevant graph concepts and marginal exchangeability. (4 sentences max.) Exercise 8 Pick one quasi-experimental study design and explain in a few sentences how it could be applied in the setting of this sleep study. (4 sentences max.) Exercise 9 (This exercise is not related to the sleep study.) Suppose that the treatment (\\(A\\)) groups are exchangeable conditional on \\(Z\\). Given the table of information below, compute the following average causal effects (showing your work): Overall ACE: \\(E[Y^{a=1} - Y^{a=0}]\\) ACE within \\(Z = A\\): \\(E[Y^{a=1} - Y^{a=0} \\mid Z = A]\\) ACE within \\(Z = B\\): \\(E[Y^{a=1} - Y^{a=0} \\mid Z = B]\\) (\\(Z\\) and \\(A\\) are binary, and \\(Y\\) is quantitative. \\(n\\) indicates the sample size for the 4 groups.) \\(n\\) \\(Z\\) \\(A\\) \\(E[Y\\mid A, Z]\\) 80 A 1 40 20 A 0 20 20 B 1 30 80 B 0 20 "],["homework-3.html", "Homework 3 Deliverables Primary objectives Retrying previous objectives", " Homework 3 Due Sunday, September 20 at midnight CST on Moodle Please turn in one knitted PDF document containing your write-up. (If you have LaTeX installed, you can knit directly to PDF (preferred method). Otherwise, you can knit to HTML and “Print” the page to save it as a PDF.) Deliverables Please turn in your write-up from the Topic 10: Applied Analysis: Regression. Primary objectives The following learning objectives are the primary focus of this assignment and are already captured in the Applied Analysis: Regression activity: REGR1: Conduct and interpret results from an appropriate regression analysis to estimate causal effects and effect modification of causal effects. CNCP1: Explain how causal and noncausal paths relate to exchangeability and causal effects. DSEP1: Apply d-separation to block noncausal paths in causal DAGs with and without unobserved variables. DSEP2: Apply strategies to deal with exchangeability problems caused by unobserved variables. DSEP4: Explain how d-separation relates to conditional exchangeability. Retrying previous objectives In order to retry previous learning objectives (listed below), you must incorporate them into the writeup for this assignment. For example, if you would like to draw a connection to randomized experiments (DESI1) at some point in your writeup, include the following in your RMarkdown file: &gt; **Revisiting objective DESI1:** Enter a response here that demonstrates that you show solid understanding of the DESI1 objective. Do the same for any other objectives that you would like to revisit. You must limit these responses to 250 words, and these responses must flow smoothly within the write up. That is, please make clear how the objective is relevant to thoughts that were described immediately beforehand. Previous objectives: EXCH1: Apply the concepts of marginal and conditional exchangeability to answer questions about (hypothetical) data on potential outcomes. EXCH2: Give examples of when marginal and conditional exchangeability would and would not hold in various data contexts. EXCH3: Explain why a direct comparison of the outcomes in the treated and untreated is misleading as an estimate of a causal effect. DESI1: Explain how randomized experiments relate to exchangeability. DESI2: Explain how quasi-experimental and general observational studies relate to exchangeability. DESI3: Compare the strengths and weaknesses of different study designs for answering a research question. PGRA1: Apply the Causal Markov assumption to express the joint distribution of data. DSEP3: Simulate data from a causal DAG under linear and logistic regression SEMs to check d-separation properties through regression modeling and visualization. "],["homework-4.html", "Homework 4 Deliverables Primary objectives Revisiting previous objectives", " Homework 4 Due Sunday, September 27 at midnight CST on Moodle Please turn in one knitted PDF document containing your write-up. (If you have LaTeX installed, you can knit directly to PDF (preferred method). Otherwise, you can knit to HTML and “Print” the page to save it as a PDF.) Deliverables Your write-up from Topic 12: Applied Analysis: Inverse Probability Weighting will form the core part of this assignment. Please add responses to the following to that writeup (all within the context of the smoking-weight gain study): Formulate a research question for in the context of the smoking-weight gain study that investigates a time-varying treatment. The “treatment” itself does not have to be smoking. Formulate a research question that would realistically be of interest in a public health setting. Indicate whether you are investigating static or dynamic treatment strategies. (Limit 300 words.) Draw and discuss a causal graph that illustrates how treatment-confounder feedback might be present. Explain why regression fails but inverse probability weighting is appropriate in this situation. Discuss causal/noncausal paths and d-separation in your response. (Limit 400 words) Primary objectives The following learning objectives are the primary focus of this assignment: IPTW1: Conduct and interpret results from an appropriate IPW analysis to estimate causal effects and effect modification of causal effects. TVTR1: Formulate research questions that can be answered in a time-varying treatment setting. TVTR2: Explain why regression does not generally work in time-varying settings with treatment-confounder feedback using d-separation ideas. CNCP1: Explain how causal and noncausal paths relate to exchangeability and causal effects. DSEP1: Apply d-separation to block noncausal paths in causal DAGs with and without unobserved variables. Revisiting previous objectives In order to revisit previous learning objectives (listed below), you must incorporate them into the writeup for this assignment. For example, if you would like to draw a connection to randomized experiments (DESI1) at some point in your writeup, include the following in your RMarkdown file: &gt; **Revisiting objective DESI1:** Enter a response here that demonstrates that you show solid understanding of the DESI1 objective. Do the same for any other objectives that you would like to revisit. You must limit these responses to 250 words, and these responses must flow smoothly within the write up. That is, please make clear how the objective is relevant to thoughts that were described immediately beforehand. You can revisit any of the following objectives (excludes REGR1). EXCH1: Apply the concepts of marginal and conditional exchangeability to answer questions about (hypothetical) data on potential outcomes. EXCH2: Give examples of when marginal and conditional exchangeability would and would not hold in various data contexts. EXCH3: Explain why a direct comparison of the outcomes in the treated and untreated is misleading as an estimate of a causal effect. DESI1: Explain how randomized experiments relate to exchangeability. DESI2: Explain how quasi-experimental and general observational studies relate to exchangeability. DESI3: Compare the strengths and weaknesses of different study designs for answering a research question. PGRA1: Apply the Causal Markov assumption to express the joint distribution of data. DSEP2: Apply strategies to deal with exchangeability problems caused by unobserved variables. DSEP3: Simulate data from a causal DAG under linear and logistic regression SEMs to check d-separation properties through regression modeling and visualization. DSEP4: Explain how d-separation relates to conditional exchangeability. "],["homework-5.html", "Homework 5 Deliverables Primary objectives Revisiting previous objectives", " Homework 5 Due Sunday, October 4 at midnight CST on Moodle Please turn in two PDF documents from class exercises. (If you have LaTeX installed, you can knit directly to PDF (preferred method). Otherwise, you can knit to HTML and “Print” the page to save it as a PDF.) Deliverables Please turn in exercises from the following class days: Topic 14: Sensitivity Analyses for Unmeasured Variables Topic 15: Causal Discovery This should be a total of two PDF documents. Primary objectives The following learning objectives are the primary focus of this assignment: SENS1: Evaluate the sensitivity of findings to data quality and propose appropriate sensitivity analyses for a research investigation SENS2: Conduct and communicate the results of a sensitivity analysis for unmeasured confounding. DISC1: Demonstrate conceptual understanding of causal discovery by reasoning about outputs of the process and by manually conducting it using regression models. DISC2: Use output from causal discovery to enhance a causal analysis as part of a sensitivity analysis. Revisiting previous objectives You can revisit any of the following objectives (excludes REGR1, IPTW1, TVTR1, and TVTR2). EXCH1: Apply the concepts of marginal and conditional exchangeability to answer questions about (hypothetical) data on potential outcomes. EXCH2: Give examples of when marginal and conditional exchangeability would and would not hold in various data contexts. EXCH3: Explain why a direct comparison of the outcomes in the treated and untreated is misleading as an estimate of a causal effect. DESI1: Explain how randomized experiments relate to exchangeability. DESI2: Explain how quasi-experimental and general observational studies relate to exchangeability. DESI3: Compare the strengths and weaknesses of different study designs for answering a research question. PGRA1: Apply the Causal Markov assumption to express the joint distribution of data. CNCP1: Explain how causal and noncausal paths relate to exchangeability and causal effects. DSEP1: Apply d-separation to block noncausal paths in causal DAGs with and without unobserved variables. DSEP2: Apply strategies to deal with exchangeability problems caused by unobserved variables. DSEP3: Simulate data from a causal DAG under linear and logistic regression SEMs to check d-separation properties through regression modeling and visualization. DSEP4: Explain how d-separation relates to conditional exchangeability. TVTR1: Formulate research questions that can be answered in a time-varying treatment setting. TVTR2: Explain why regression does not generally work in time-varying settings with treatment-confounder feedback using d-separation ideas. If you revisit any of these objectives, you must do so using the graph below. If revisiting an objective requires context for exactly what these variables represent, feel free to pick a context that is suitable for you. library(dagitty) dag &lt;- dagitty(&quot;dag { bb=\\&quot;0,0,1,1\\&quot; A [exposure,pos=\\&quot;0.400,0.350\\&quot;] L [pos=\\&quot;0.200,0.350\\&quot;] U1 [latent,pos=\\&quot;0.100,0.200\\&quot;] U2 [latent,pos=\\&quot;0.100,0.500\\&quot;] Y [outcome,pos=\\&quot;0.600,0.350\\&quot;] A -&gt; Y L -&gt; A U1 -&gt; L U1 -&gt; Y U2 -&gt; A U2 -&gt; L } &quot;) plot(dag) "],["final-project.html", "Final Project Deliverables Option 1: Data analysis Option 2: Blog posts Option 3: Learn an advanced topic Option 4: Other", " Final Project There are a number of options available for the final project. Grading scale: Not Assessable Needs Revisions Meets Expectations Excellent Deliverables For all projects below, the only deliverable is a “digital artifact” that could be used for the digital capstone showcase. A digital artifact can take any of the following forms: A video presentation A podcast-style recording A set of blog posts Work with Leslie to determine the most suitable form for your digital artifact, depending on the option you pick. In order to earn an Excellent, your artifact must be presented in a way that is clear and engaging for a student who has only completed STAT 155. Not every part of the artifact should be easily understood by an introductory student, but they should be able to take away some understanding even from the more advanced material. Option 1: Data analysis Collaboration: Groups of up to 3. Individual work is fine. Perform a causal analysis on a dataset of your choice. To earn an Excellent, the analysis must contain one major component per team member. Options for major components: Regression analysis for causal effect estimation with a sensitivity analysis for unmeasured confounding Inverse probability weighting analysis for causal effect estimation with a sensitivity analysis for unmeasured confounding Causal discovery as a sensitivity analysis (Information on the pcalg R package for causal discovery will be added to our website’s appendix.) Mediation analysis for causal effect estimation Instrumental variables analysis Resources for finding data: Google Dataset Search Harvard Dataverse Inter-university Consortium for Political and Social Research (ICPSR) IPUMS Option 2: Blog posts Collaboration: Individual only. Write two blog posts explaining causal inference ideas to a general audience. The first post should address one of the three topics below. Estrogens and uterine cancer example of selection bias: see Graphical Structure of Selection Bias, Exercise 3. The smoking-birth weight paradox Pick any media item that has interested you. Write a reaction to it / an analysis of it from a causal inference perspective. If you’re looking to explore some media, the Casual Inference podcast is a fun one! The second post should be a “tour of causal inference” and lead the reader through all topics covered in our course in a cohesive story. Option 3: Learn an advanced topic Collaboration: Groups of up to 3. Individual work is fine. Dig deeper into course topics or learn a new topic. Examples could include: Methods for transportability (generalizability) of effects Interference Details of methods for time-varying treatments Specialized considerations for particular study designs Option 4: Other If none of these options piques your interest, I’m happy to discuss alternatives with you. "],["additional-r-resources.html", "Additional R resources", " Additional R resources DAGitty does not display noncausal paths, which can often be helpful for trying to approximately block noncausal paths in the presence of unmeasured variables. The code below shows a way to do this. For now, you have to define the DAG using a list of edges. (The example below shows the classic confounder triangle.) If you’re feeling adventurous, learn about the dagitty R package to see if you can write a function that takes the “Model code” from the DAGitty web interface (right side of the window) to directly create the igraph object. library(igraph) # Create the edge list el &lt;- rbind( c(&quot;C&quot;, &quot;A&quot;), c(&quot;A&quot;, &quot;Y&quot;), c(&quot;C&quot;, &quot;Y&quot;) ) # Create the graph dag &lt;- graph_from_edgelist(el, directed = TRUE) # Helper functions for displaying paths display_paths &lt;- function(g, paths) { adj &lt;- as_adjacency_matrix(g) for (i in seq_along(paths)) { path &lt;- paths[[i]] cat(&quot;Path &quot;, i, &quot;: &quot;, sep = &quot;&quot;) draw_edge(adj_mat = adj, path = path) } } draw_edge &lt;- function(adj_mat, path) { path_ids &lt;- as_ids(path) arrow_vec &lt;- rep(&quot;&quot;, length(path_ids)) for (i in seq_len(length(path_ids)-1)) { node1 &lt;- path_ids[i] node2 &lt;- path_ids[i+1] if (adj_mat[node1,node2]==1) { ## Arrow is 1 -&gt; 2 arrow_vec[i] &lt;- &quot;-&gt;&quot; } else { ## Arrow is 1 &lt;- 2 arrow_vec[i] &lt;- &quot;&lt;-&quot; } } path_string &lt;- paste(path_ids, arrow_vec) path_string &lt;- paste(path_string, collapse = &quot; &quot;) cat(path_string, &quot;\\n&quot;) } display_paths(dag, all_simple_paths(dag, from = &quot;A&quot;, to = &quot;Y&quot;, mode = &quot;all&quot;)) "]]
